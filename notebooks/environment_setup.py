import numpy as np
import pandas as pd
import random
import gym
from gym import spaces

class ActivityPatterns:
    """Classe pour g√©rer les mod√®les d'activit√©s et pr√©f√©rences temporelles"""
    
    def __init__(self, data):
        self.data = data
        self._initialize_patterns()
        
    def _initialize_patterns(self):
        """Initialise les mod√®les d'activit√©s √† partir des donn√©es"""
        # Calculer les distributions horaires pour chaque activit√©
        self.activity_time_prefs = {}
        
        # Assurez-vous que 'hour' et 'ACTIVITY_NAME_ENC' existent dans les donn√©es
        if 'hour' in self.data.columns and 'ACTIVITY_NAME_ENC' in self.data.columns:
            # Pour chaque activit√©, calculer sa distribution par heure
            for activity in self.data['ACTIVITY_NAME_ENC'].unique():
                activity_data = self.data[self.data['ACTIVITY_NAME_ENC'] == activity]
                hour_dist = activity_data['hour'].value_counts(normalize=True).sort_index()
                
                # Remplir les heures manquantes avec des z√©ros
                all_hours = pd.Series(0.0, index=range(24))
                for hour, freq in hour_dist.items():
                    if 0 <= hour < 24:  # V√©rifier que l'heure est valide
                        all_hours[hour] = freq
                
                self.activity_time_prefs[activity] = all_hours

    def get_time_preference_score(self, activity, hour):
        """Retourne un score de pr√©f√©rence pour l'activit√© √† l'heure donn√©e"""
        if activity in self.activity_time_prefs and 0 <= hour < 24:
            return self.activity_time_prefs[activity][hour]
        return 0.01  # Score par d√©faut faible mais non nul

    def get_activity_sequence_score(self, activity1, activity2):
        """√âvalue la pertinence de la s√©quence entre deux activit√©s"""
        # Vous pourriez impl√©menter ici une logique pour √©valuer
        # si activity2 suit bien activity1 (bas√© sur les donn√©es)
        return 0.5  # Valeur neutre par d√©faut


class ScheduleEnv(gym.Env):
    """
    Environnement pour l'optimisation de planning avec apprentissage par renforcement
    """
    
    def __init__(self, data, num_slots=24):
        super(ScheduleEnv, self).__init__()
        
        self.data = data
        self.num_slots = num_slots
        
        # Sauvegarder les activit√©s uniques
        self.unique_activities = sorted(data['ACTIVITY_NAME_ENC'].unique())
        self.num_activities = len(self.unique_activities)
        
        # Dictionnaire pour mapper les codes aux noms d'activit√©s
        # Cette partie est facultative et d√©pend de la pr√©sence de 'ACTIVITY_NAME' dans vos donn√©es
        if 'ACTIVITY_NAME' in data.columns:
            self.activity_names = {}
            for act_code in self.unique_activities:
                act_name = data[data['ACTIVITY_NAME_ENC'] == act_code]['ACTIVITY_NAME'].iloc[0]
                self.activity_names[act_code] = act_name
        else:
            # Si pas de noms d'activit√©s, utiliser les codes comme noms
            self.activity_names = {act: f"Activity {act}" for act in self.unique_activities}
        
        # Action : choisir une activit√© pour un slot
        self.action_space = spaces.Discrete(self.num_activities)
        
        # Observation : 
        # - Slot horaire actuel (24 possibilit√©s)
        # - Jour de la semaine (7 possibilit√©s)
        # - Derni√®re activit√© choisie (num_activities possibilit√©s)
        # - Indicateur d'activit√©s d√©j√† planifi√©es (vecteur binaire)
        obs_dim = 3 + self.num_slots  # slot actuel + jour + derni√®re action + activit√©s planifi√©es
        self.observation_space = spaces.Box(low=0, high=1, shape=(obs_dim,), dtype=np.float32)
        
        # Analyser les mod√®les d'activit√©s
        self.activity_patterns = ActivityPatterns(data)
        
        # Initialiser l'√©tat
        self.reset()

    def reset(self):
        """R√©initialise l'environnement √† un √©tat initial"""
        self.current_slot = 0
        self.schedule = np.zeros(self.num_slots, dtype=np.int32)
        self.day_of_week = random.randint(0, 6)
        self.last_activity = 0  # Aucune activit√© pr√©c√©dente
        
        return self._get_observation()

    def _get_observation(self):
        """Retourne l'observation actuelle"""
        # Normaliser le slot pour qu'il soit entre 0 et 1
        slot_normalized = self.current_slot / self.num_slots
        
        # Normaliser le jour de la semaine
        day_normalized = self.day_of_week / 6
        
        # Normaliser la derni√®re activit√©
        last_act_normalized = self.last_activity / (self.num_activities - 1) if self.num_activities > 1 else 0
        
        # Cr√©er un vecteur binaire indiquant les activit√©s d√©j√† planifi√©es
        planned_activities = np.zeros(self.num_slots)
        for i in range(self.current_slot):
            planned_activities[i] = 1
        
        # Combiner les composants pour former l'observation compl√®te
        observation = np.concatenate([[slot_normalized, day_normalized, last_act_normalized], planned_activities])
        
        return observation

    def step(self, action):
        """
        Ex√©cuter une action (choisir une activit√© pour le slot courant)
        """
        # V√©rifier la validit√© de l'action
        if not self.action_space.contains(action):
            action = random.randint(0, self.num_activities - 1)
        
        # Stocker l'activit√© dans le planning
        self.schedule[self.current_slot] = action
        
        # Calculer la r√©compense
        reward = self._calculate_reward(action, self.current_slot)
        
        # Mettre √† jour l'√©tat
        self.last_activity = action
        self.current_slot += 1
        
        # V√©rifier si l'√©pisode est termin√©
        done = self.current_slot >= self.num_slots
        
        # Obtenir la nouvelle observation
        observation = self._get_observation()
        
        # Informations suppl√©mentaires (pour d√©bogage)
        info = {
            'current_slot': self.current_slot,
            'day_of_week': self.day_of_week,
            'activity': action
        }
        
        return observation, reward, done, info

    def _calculate_reward(self, action, time_slot):
        """Calcule la r√©compense pour l'action choisie"""
        reward = 0.0
        
        # R√©compense bas√©e sur les pr√©f√©rences horaires
        time_pref_score = self.activity_patterns.get_time_preference_score(action, time_slot)
        reward += time_pref_score * 2.0
        
        # R√©compense bas√©e sur la s√©quence d'activit√©s
        if time_slot > 0:
            previous_action = self.schedule[time_slot - 1]
            sequence_score = self.activity_patterns.get_activity_sequence_score(previous_action, action)
            reward += sequence_score
        
        # Pour √©viter des r√©compenses trop faibles
        reward = max(reward, 0.1)
        
        return reward

    def get_activity_name(self, activity_code):
        """Retourne le nom de l'activit√© correspondant au code"""
        return self.activity_names.get(activity_code, f"Activity {activity_code}")

    def render(self, mode='human'):
        """Affiche l'√©tat actuel du planning"""
        if mode == 'human':
            print(f"üïí Slot actuel: {self.current_slot}/{self.num_slots}")
            print(f"üìÖ Jour: {['Dim', 'Lun', 'Mar', 'Mer', 'Jeu', 'Ven', 'Sam'][self.day_of_week]}")
            print("üìã Planning actuel:")
            
            for i, act in enumerate(self.schedule):
                if i < self.current_slot:
                    print(f"  {i:02d}:00 - {self.get_activity_name(act)}")
                else:
                    print(f"  {i:02d}:00 - [Non planifi√©]")
            
            print("")
        
        return None